<!DOCTYPE html>
<html>
<meta charset="utf-8" />
<title>Linux Performance Tuning</title>
<xmp theme="readable" style="display:none;" toc="true">
![img](http://www.brendangregg.com/Perf/linux_perf_tools_full.png)

## tools install
apt install:

* `stress` / `stress-ng`
* `sysstat`
* `dstat`
* `sysbench`
* `linux-tools-common`: perf
* `apache2-utils`: ab
* [hey](https://github.com/rakyll/hey)
* [wrk](https://github.com/wg/wrk)
* [perf-tools](https://github.com/brendangregg/perf-tools): execsnoop
* `sar`
* `tcpdump`
* `hping3`
* [htop](http://htop.sourceforge.net/)
* [atop](http://www.atoptool.nl/)
* `iftop`
* `nethogs`
* [bcc](https://github.com/iovisor/bcc): cachestat, cachetop, memleak, filetop, opensnoop
* [pcstat](https://github.com/tobert/pcstat)
* `vmtouch`
* `net-tools`: ifconfig, route, arp, netstat, traceroute, mtr
* [iproute2](https://en.wikipedia.org/wiki/Iproute2): ip, ss
* `iptables`
* `conntrack`
* `ethtool`
* `iputils-ping`
* `dnsutils`: dig, host, nslookup, whois
* `pciutils`
* `lsof`
* `iperf3`
* `netperf`
* `fio`
* `ioping`
* `blktrace`: blktrace, blkparse
* `trace-cmd`
* [sysdig](https://github.com/draios/sysdig)

# General
## uptime
```
$ uptime
19:38:53 up 4 days,  2:58,  1 user,  load average: 0.00, 0.00, 0.00
```
load average:  1, 5, 15分钟

[平均负载](http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html)
> the number of threads that are working and waiting to work (CPU, disk, uninterruptible locks). Put differently, it measures the number of threads that aren't completely idle.


## pidstat
进程 CPU 利用
```
$ pidstat -u 3 1
Linux 4.4.0-116-generic (ubuntu) 	08/25/2019 	_x86_64_	(2 CPU)

10:29:53 AM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
10:29:56 AM     0      1193    0.33    0.00    0.00    0.00    0.33     1  docker-containe

Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        0      1193    0.33    0.00    0.00    0.00    0.33     -  docker-containe
```

* %usr: 用户态
* %system: 内核态
* %guest: 虚拟化（运行虚拟机）
* %wait: 等待 CPU
* %CPU: 总计

进程上下文切换
```
pidstat -w 3 1
Linux 4.4.0-116-generic (ubuntu) 	06/19/2019 	_x86_64_	(2 CPU)

08:17:45 PM   UID       PID   cswch/s nvcswch/s  Command
08:17:48 PM     0         7      1.67      0.00  rcu_sched
08:17:48 PM     0      1045      6.67      0.00  dockerd
08:17:48 PM     0      1061      1.00      0.00  iscsid
08:17:48 PM     0      1062      3.67      0.00  iscsid
08:17:48 PM   111      1158      1.00      0.00  ntpd
08:17:48 PM     0     20572      1.67      0.00  kworker/1:2
08:17:48 PM     0     21772      0.67      0.00  kworker/0:1
08:17:48 PM     0     22643      7.00      0.00  kworker/u4:2
08:17:48 PM     0     22685      0.33      0.00  pidstat
```
* cswch: 自愿切换
* nvcswch: 非自愿切换

I/O
```
$ pidstat -d 3 1
Linux 4.4.0-116-generic (ubuntu) 	07/14/2019 	_x86_64_	(2 CPU)

09:40:34 PM   UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
09:40:37 PM     0      7741      0.00     69.10     69.10       0  apt-get
09:40:37 PM   105      7747      0.00    150.17      0.00       0  http
09:40:37 PM   105      7748      0.00     95.68      0.00       0  http
09:40:37 PM   105      7751      0.00     47.84     47.84       0  gpgv
09:40:37 PM   105      8020      0.00   1585.38      0.00       0  store
```

* kB_rd/s: 每秒读
* kB_wr/s: 每秒写
* kB_ccwr/s: cancelled 被取消的写
* iodelay: I/O 延迟，单位时钟周期

内存
```
pidstat -r 3 1
Linux 4.4.0-116-generic (ubuntu) 	08/30/2019 	_x86_64_	(2 CPU)

10:22:46 AM   UID       PID  minflt/s  majflt/s     VSZ     RSS   %MEM  Command
10:22:49 AM     0      8231    280.73      0.00   12420    4796   0.12  pidstat
```

## top
`cat /proc/{pid}/status`
```
$ top
top - 20:14:01 up 10 days,  9:37,  1 user,  load average: 0.00, 0.00, 0.00
Tasks: 107 total,   1 running, 106 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.2 us,  0.3 sy,  0.0 ni, 99.5 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  4046388 total,  3093660 free,   112336 used,   840392 buff/cache
KiB Swap:   998396 total,   998396 free,        0 used.  3653864 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    1 root      20   0   38052   6060   3968 S   0.0  0.1   0:06.38 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.11 kthreadd
```

* `1` 显示每个 CPU core，`I` CPU 百分比是否按单个 CPU 显示
* 按 `f` 增减项, `F` 按某项排序，`H` 显示线程信息(此时PID显示的实际上是LWPID，或用ps aux -L)
* `M` 按memory排序，`P` 按cpu排序，`N` 按PID排序


* VIRT (Virtual Image): 进程使用的虚拟内存
* RES (Resident size): 进程实际使用的物理内存
* SHR (Shared Mem size): 进程使用的共享内存，即可以和其他进程共享的内存空间（动态库）
* SWAP (Swapped Size): 交换内存
* CODE (Code size): 进程的程序代码占用物理内存大小，也叫 text resident set (TRS)
* DATA (Data+Stack size): 进程的非程序代码部份占用物理内存大小，也叫 data resident set (DRS)
* %MEM: RES 占总内存的比例

## vmstat
上下文切换、中断
```
$ vmstat 3
procs -----------memory----------  ---swap--  -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache    si   so    bi    bo   in   cs us sy  id wa st
 0  0      0 3188180  86228 661360    0    0     1     4   34   11  0  0 100  0  0
```
第一行是系统启动以来的平均值（procs, memory除外）。

* procs
  * r 运行或等待 CPU 进程数
  * b 不可中断进程数
* memory 单位KB
  * swpd
  * free
  * buff
  * cache
* swap
  * si
  * so
* io 块设备IO，单位块/秒（等于KB/s）
  * bi 读
  * bo 写
* system
  * in 每秒中断次数
  * cs 每秒上下文切换次数
* cpu
  * us user
  * sy system
  * id idle
  * wa iowait
  * st stolen

## ps
```
$ ps aux
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.1  38052  6060 ?        Ss   Jul04   0:06 /sbin/init
root         2  0.0  0.0      0     0 ?        S    Jul04   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    Jul04   0:00 [ksoftirqd/0]
```

STAT 进程状态：

* R(Running): 正在运行或等待运行
* D(Disk Sleep): 正在和硬件交互，不可中断。（不可中断睡眠）
* Z(Zombie): 僵尸进程
* S(Interruptible Sleep): 可中断睡眠
* I(Idle): 空闲
* T(Stopped): SIGSTOP 导致暂停
* t(Traced): 用调试器中断进程后
* X(Dead): 已消亡

s: 会话领导进程
+: 前台进程组
l: 多线程
<: 高优先级
N: 低优先级
L: 有页锁在内存

RSS (Resident Set Size): 常驻内存集，包括共享内存, in KiB。

## sar
```
$ sar -n DEV 1
Linux 4.4.0-116-generic (ubuntu) 	07/14/2019 	_x86_64_	(2 CPU)

10:24:27 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
10:24:28 PM    enp0s3      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
10:24:28 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
```

* rxpck/s: 每秒接收帧数
* txpck/s: 每秒发送帧数
* rxkB/s: 每秒接收字节数
* txkB/s: 每秒发送字节数
* rxcmp/s: 接收压缩帧数
* txcmp/s: 发送压缩帧数
* %ifutil: 接口使用率 max(rxkB, txkB)/Bandwidth

```
$ sar -d 1
Linux 4.4.0-116-generic (ubuntu) 	07/14/2019 	_x86_64_	(2 CPU)

10:48:49 PM       DEV       tps  rd_sec/s  wr_sec/s  avgrq-sz  avgqu-sz     await     svctm     %util
10:48:50 PM   dev11-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
10:48:50 PM    dev8-0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
```

```
sar -r 1
Linux 4.4.0-116-generic (ubuntu) 	07/21/2019 	_x86_64_	(2 CPU)

09:34:48 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
09:34:49 PM   2983488   1062900     26.27    127756    711256    515420     10.22    706272    211684         0
09:34:50 PM   2983488   1062900     26.27    127756    711256    515420     10.22    706328    211684         0
```

* commit: 当前系统负载需要的内存
* active: 活跃内存
* inact: 不活跃内存，可能会被回收


# CPU
## mpstat
CPU 性能指标 `cat /proc/stat | grep ^cpu`
```
$ mpstat -P ALL
Linux 4.4.0-116-generic (ubuntu) 	06/19/2019 	_x86_64_	(2 CPU)

07:39:40 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
07:39:40 PM  all    0.17    0.01    0.11    0.00    0.00    0.00    0.00    0.00    0.00   99.71
07:39:40 PM    0    0.17    0.01    0.10    0.00    0.00    0.00    0.00    0.00    0.00   99.71
07:39:40 PM    1    0.16    0.01    0.11    0.01    0.00    0.00    0.00    0.00    0.00   99.71
```

* usr: 用户态
* nice: 低优先级用户态 (nice 1-19)
* sys: 内核态
* iowait: 等待IO
* irq: 处理中断
* soft: 处理软中断
* steal: 被其他虚拟机占用
* guest: 虚拟化（运行虚拟机）
* gnice: 低优先级运行虚拟机
* idle: 空闲

# IO
## iostat
```
$ iostat -d -x 1
Linux 4.4.0-116-generic (ubuntu) 	07/22/2019 	_x86_64_	(2 CPU)

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
scd0              0.00     0.00    0.00    0.00     0.00     0.00     8.00     0.00    0.50    0.50    0.00   0.50   0.00
sda               0.00     0.06    0.03    0.05     0.60     7.26   195.02     0.00    5.40    0.90    7.93   0.47   0.00
```

* rrqm/s: 每秒合并的读请求数
* wrqm/s: 每秒合并的写请求数
* r/s: 每秒读请求数（合并后）
* w/s: 每秒写请求数（合并后）
* rkB/s: 每秒读取数据量
* wkB/s: 每秒写入数据量
* r_await: 读请求处理完成等待时间（包括队列中的等待时间, ms）
* w_await: 写请求处理完成等待时间（包括队列中的等待时间, ms）
* avgqu-sz: 平均请求队列长度(kB)
* avgrq-sz: 平均读请求大小(kB)
* svctm: 处理 IO 请求所需的平均时间（不包括等待时间，ms）
* %util: 使用率，处理 IO 的时间百分比，100% 不代表饱和

## slabtop
`cat /proc/slabinfo`
```
$ slabtop
 Active / Total Objects (% used)    : 361549 / 364804 (99.1%)
 Active / Total Slabs (% used)      : 14066 / 14066 (100.0%)
 Active / Total Caches (% used)     : 75 / 121 (62.0%)
 Active / Total Size (% used)       : 108008.02K / 109114.62K (99.0%)
 Minimum / Average / Maximum Object : 0.01K / 0.30K / 8.00K

  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME
 83769  83710  99%    0.19K   3989       21     15956K dentry
 83070  83070 100%    0.10K   2130       39      8520K buffer_head
 48810  48685  99%    1.05K   3254       15     52064K ext4_inode_cache
 27778  27728  99%    0.12K    817       34      3268K kernfs_node_cache
 22950  21871  95%    0.04K    225      102       900K ext4_extent_status
 16618  16618 100%    0.55K   1187       14      9496K inode_cache
```

## iotop
```
$ iotop
Total DISK READ :       0.00 B/s | Total DISK WRITE :       0.00 B/s
Actual DISK READ:       0.00 B/s | Actual DISK WRITE:       0.00 B/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND
17473 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.03 % [kworker/u4:0]
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
    2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]
    3 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]
    5 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H]
    7 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]
    8 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_bh]
    9 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]
```


## df
```
$ df -ihT
Filesystem           Type     Inodes IUsed IFree IUse% Mounted on
udev                 devtmpfs   489K   431  489K    1% /dev
tmpfs                tmpfs      494K   595  494K    1% /run
/dev/sda1            ext4       6.2M  389K  5.9M    7% /
```

## du
```
$ du -hc --max-depth=1
104M	./test
11M	./.kube
1.9G	./.local
```


# Memory
## free
`cat /proc/meminfo`
```
$ free -h
              total        used        free      shared  buff/cache   available
Mem:           3.9G        116M        2.9G         20M        867M        3.5G
Swap:          974M
```

* total: 总内存
* used: 已使用内存，包含共享内存
* free: 未使用内存
* shared: 共享内存
* buff/cache: 缓存，内核两种不区分(https://lwn.net/Articles/712467), 对于文件 cache 指向 buff
  * (block) buff: 块设备缓存
  * (page) cache: 页（文件系统）缓存
* available: 可用内存（未使用内存+可回收缓存）

# Networking
## iftop

## netstat/ss
```
$ ss -ltnp
State      Recv-Q Send-Q                                                                         Local Address:Port                                                                                        Peer Address:Port
LISTEN     0      128                                                                                        *:22                                                                                                     *:*                   users:(("sshd",pid=1046,fd=3))
LISTEN     0      128                                                                                       :::22                                                                                                    :::*                   users:(("sshd",pid=1046,fd=4))
```

State: socket 状态

* ESTABLISHED
  * Recv-Q: 接收队列长度（字节数）
  * Send-Q: 发送队列长度（字节数）
* LISTEN
  * Recv-Q: ack backlog（全连接队列） 当前值
  * Send-Q: 最大 ack backlog 值

```
$ ss -s
Total: 131 (kernel 180)
TCP:   3 (estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 0

Transport Total     IP        IPv6
*         180       -         -
RAW       0         0         0
UDP       7         4         3
TCP       3         2         1
INET      10        6         4
FRAG      0         0         0
```

```
$ netstat -s
Ip:
    28593 total packets received
    2 with invalid addresses
    0 forwarded
    0 incoming packets discarded
    28546 incoming packets delivered
    21729 requests sent out
Icmp:
    2 ICMP messages received
    0 input ICMP message failed.
    ICMP input histogram:
        destination unreachable: 2
    4 ICMP messages sent
    0 ICMP messages failed
    ICMP output histogram:
        destination unreachable: 4
IcmpMsg:
        InType3: 2
        OutType3: 4
Tcp:
    66 active connections openings
    9 passive connection openings
    0 failed connection attempts
    2 connection resets received
    1 connections established
    26873 segments received
    20350 segments send out
    3 segments retransmited
    0 bad segments received.
    39 resets sent
Udp:
    1668 packets received
    3 packets to unknown port received.
    0 packet receive errors
    1954 packets sent
UdpLite:
TcpExt:
    29 TCP sockets finished time wait in fast timer
    109 delayed acks sent
    1 delayed acks further delayed because of locked socket
    17459 packet headers predicted
    120 acknowledgments not containing data payload received
    6484 predicted acknowledgments
    3 congestion windows recovered without slow start after partial ack
    3 other TCP timeouts
    2 connections reset due to early user close
    TCPRcvCoalesce: 8673
    TCPAutoCorking: 124
    TCPSynRetrans: 3
    TCPOrigDataSent: 6610
    TCPHystartTrainDetect: 3
    TCPHystartTrainCwnd: 52
    TCPKeepAlive: 16
IpExt:
    InNoRoutes: 45
    InOctets: 80937971
    OutOctets: 2903583
    InNoECTPkts: 67780
```

```
$ netstat -i
Kernel Interface table
Iface       MTU Met   RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
docker0    1500 0         0      0      0 0             0      0      0      0 BMU
enp0s3     1500 0     68142      0      0 0         22828      0      0      0 BMRU
lo        65536 0         1      0      0 0             1      0      0      0 LRU
```

* RX-OK/TX-OK: 收发总包数
* RX-ERR/TX-ERR: 收发错误数
* RX-DRP/TX-DRP: 进入 buffer 后的丢包数
* RX-OVR/TX-OVR: buffer 溢出的丢包数


## [ip](https://helpmanual.io/man8/ip/)
[subcommands](https://events.static.linuxfound.org/sites/events/files/slides/2016%20-%20Linux%20Networking%20explained_0.pdf):

* addr(ess): ip 地址
* route: 路由
* link: 网络设备
* netns: 网络空间
* tuntap: 用户空间网关，L2(TAP), L3(TUN)
* neigh: ARP

### ip-addr
```
$ ip -s addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
    RX: bytes  packets  errors  dropped overrun mcast
    0          0        0       0       0       0
    TX: bytes  packets  errors  dropped carrier collsns
    0          0        0       0       0       0
2: enp0s3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:b2:d8:0b brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global enp0s3
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:feb2:d80b/64 scope link
       valid_lft forever preferred_lft forever
    RX: bytes  packets  errors  dropped overrun mcast
    1170418    2925     0       0       0       0
    TX: bytes  packets  errors  dropped carrier collsns
    245510     2186     0       0       0       0
```

RX: 收
TX: 发

* errors: 错误的包
* dropped: 丢弃的包
* overrun: ring buffer 满丢包
* mcast: 多播包
* carrier: 物理载体错误
* collsns: 碰撞的包


### ip-route
`cat /etc/iproute2/rt_tables` 查看所有路由表，local优先于main
`ip route list table <main/local>`, `ip route/route -n` (查看main)
指定路由查找 `ip route get 192.168.10.10`

### ip-link
type:

* bridge: Virtual Switch
* bond: Link Aggregation
* veth: Virtual Ethernet Cable Peer
* vxlan
* vlan: 二层vlan
* macvlan
* ipvlan
* ipip

查看类型：[ip link show type](https://unix.stackexchange.com/questions/272850/how-to-determine-the-logical-type-of-a-linux-network-device)

### ip-netns
`ip netns` 默认看不到docker netns，需要[symlink](https://stackoverflow.com/questions/31265993/docker-networking-namespace-not-visible-in-ip-netns-list)。
查看veth peer：`ethtool -S`，需到对应ns才能看到 `nsenter -t <contanier_pid> -n ip link`。

## [iptables](https://wiki.archlinux.org/index.php/iptables)
[iptables-tutorial](https://www.frozentux.net/iptables-tutorial/chunkyhtml/index.html)
[iptable_vis](https://github.com/Nudin/iptable_vis)

命令：`iptables [-t table] command chain [rule-num] rule-spec -j target`

chains: 规则链

* PREROUTING (路由前)
* INPUT (数据包入口)
* FORWARD (转发管道)
* OUTPUT(数据包出口)
* POSTROUTING（路由后）

```bash
                               XXXXXXXXXXXXXXXXXX
                             XXX     Network    XXX
                               XXXXXXXXXXXXXXXXXX
                                       +
                                       |
                                       v
 +-------------+              +------------------+
 |table: filter| <---+        | table: nat       |
 |chain: INPUT |     |        | chain: PREROUTING|
 +-----+-------+     |        +--------+---------+
       |             |                 |
       v             |                 v
 [local process]     |           ****************          +--------------+
       |             +---------+ Routing decision +------> |table: filter |
       v                         ****************          |chain: FORWARD|
****************                                           +------+-------+
Routing decision                                                  |
****************                                                  |
       |                                                          |
       v                        ****************                  |
+-------------+       +------>  Routing decision  <---------------+
|table: nat   |       |         ****************
|chain: OUTPUT|       |               +
+-----+-------+       |               |
      |               |               v
      v               |      +-------------------+
+--------------+      |      | table: nat        |
|table: filter | +----+      | chain: POSTROUTING|
|chain: OUTPUT |             +--------+----------+
+--------------+                      |
                                      v
                               XXXXXXXXXXXXXXXXXX
                             XXX    Network     XXX
                               XXXXXXXXXXXXXXXXXX
```

[Packet flow](https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg)

tables:

* filter: 规定允许还是不允许（默认），应用于INPUT/FORWARD/OUTPUT
* nat: 定义地址转换，应用于PREROUTING/OUTPUT/POSTROUTING
* mangle: 修改报文数据，五个链都可以

commands:

* A: append, 增加规则
* C: check, 检查规则存不存在
* D: delete, 删除规则
* R: replace, 替换规则
* I: insert, 插入规则
* L: list, 列出规则或链
* S: 打印规则或链的命令列表
* F: flush, 清空规则或链
* P: policy, 设置链的默认策略（不符合条件时）
* Z: 重置链中默认规则的命中计数器
* N: new, 新建自定义链
* X: 删除自定义链
* E: 重命名自定义链

targets:

* DROP: 丢弃（终止）
* REJECT: 拒绝（终止）
* ACCEPT: 接受（next chain）
* DNAT （next chain）
* SNAT （next chain）
* MASQUERADE：源地址伪装 （next chain）
* REDIRECT：端口重定向 （next rule）
* MARK: 打标记 （next rule）
* RETURN: 返回原规则链 （next rule）
* TRACE
* chain-name: 转向自定义链 （next chain）

rule-specs:
在一个 chain 中自上而下匹配，匹配到执行 targets，如果没找到匹配就返回原 chain 继续匹配。

* s: source, 源地址，IP[/MASK] 可以加上`!`取反
* d: dest, 目标地址
* p: protocol, 协议，TCP/UDP/ICMP
    * sport: 源端口
    * dport: 目标端口
    * tcp-flag: tcp标识位
    * icmp-type: icmp消息类型
* i: 流入的网络接口，用于INPUT/PREROUTING
* o: 流出的网络接口，用于OUTPUT/POSTROUTING
* m: match扩展，[用于FORWARD](https://www.digitalocean.com/community/tutorials/how-to-forward-ports-through-a-linux-gateway-with-iptables)
    * state: --state NEW/ESTABLISHED/RELATED/INVALID
    * conntrack: --ctstate NEW/ESTABLISHED/RELATED/INVALID

SNAT(源地址的转换)/MASQUERADE(伪装)：POSTROUTING
把内网某个网段的地址在经过时转为外网地址（源端口不变，若有数据发回时从外网地址映射回内网地址UN-SNAT）：
`iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j SNAT --to-source 142.10.0.1`
如果外网地址不固定，使用MASQUERADE可以自动从网卡获取外网地址：
`iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE`
场景：局域网共享一个公网IP上网

DNAT(目标地址转换)：PREROUTING/OUTPUT
访问外网IP时转向内网主机（同一连接上有数据返回时，从内网地址映射回外网地址UN-DNAT, 在类似 POSTROUTING 阶段进行，但不经过 POSTROUTING 处理，SNAT 同理）：
`iptables -t nat -A PREROUTING -d 142.10.0.1 -p tcp --dport 80 -j DNAT --to-destination 192.168.0.2:80`
场景：端口映射，以让外部访问内网

同一个流上的包只会被iptables NAT判断一次，以后的包根据 conntrack 自动NAT。

TRACE
在`/var/log/syslog`中查看日志。格式：`TRACE: tablename:chainname:type:rulenum`
`iptables -t raw -A PREROUTING -p icmp -j TRACE`
需要设置：
```
modprobe nf_log_ipv4
sysctl net.netfilter.nf_log.2=nf_log_ipv4
```

使用 iptables 需要开启转发：
```
sysctl net.ipv4.ip_forward = 1
```

## conntrack
```
$ conntrack -L -o extended
ipv4     2 udp      17 32 src=10.0.2.15 dst=193.228.143.12 sport=123 dport=123 src=193.228.143.12 dst=10.0.2.15 sport=123 dport=123 [ASSURED] mark=0 use=1
ipv4     2 udp      17 29 src=10.0.2.15 dst=185.255.55.20 sport=123 dport=123 src=185.255.55.20 dst=10.0.2.15 sport=123 dport=123 mark=0 use=1
ipv4     2 tcp      6 100 TIME_WAIT src=10.0.2.15 dst=59.111.0.251 sport=36334 dport=80 src=59.111.0.251 dst=10.0.2.15 sport=80 dport=36334 [ASSURED] mark=0 use=1
ipv4     2 tcp      6 432000 ESTABLISHED src=10.0.2.2 dst=10.0.2.15 sport=60669 dport=22 src=10.0.2.15 dst=10.0.2.2 sport=22 dport=60669 [ASSURED] mark=0 use=1
ipv4     2 udp      17 56 src=10.0.2.15 dst=158.43.128.33 sport=123 dport=123 src=158.43.128.33 dst=10.0.2.15 sport=123 dport=123 [ASSURED] mark=0 use=1
ipv4     2 udp      17 9 src=10.0.2.15 dst=192.168.1.1 sport=60206 dport=53 src=192.168.1.1 dst=10.0.2.15 sport=53 dport=60206 mark=0 use=1
ipv4     2 udp      17 159 src=10.0.2.15 dst=192.168.1.1 sport=52215 dport=53 src=192.168.1.1 dst=10.0.2.15 sport=53 dport=52215 [ASSURED] mark=0 use=1
ipv4     2 udp      17 11 src=10.0.2.15 dst=116.203.151.74 sport=123 dport=123 src=116.203.151.74 dst=10.0.2.15 sport=123 dport=123 mark=0 use=1
```

* 如果报文匹配到一个 NAT 规则，例如 IP 地址伪装，相应的映射信息会记录在链接跟踪项的回复方向部分，并自动应用于同一条流的所有后续报文。
* 即使一条流经过了地址或端口的转换，也可以成功在连接状态表中查找到回复报文的四元组信息。

```
tcp      6 117 TIME_WAIT src=100.115.93.210 dst=100.115.93.222 sport=38532 dport=8000 src=172.17.0.101 dst=100.115.93.210 sport=8080 dport=38532 [ASSURED] mark=0 use=1
tcp      6 116 TIME_WAIT src=172.17.0.101 dst=100.115.93.210 sport=59982 dport=8080 src=100.115.93.210 dst=100.115.93.222 sport=8080 dport=59982 [ASSURED] mark=0 use=1
```
第一条 DNAT：`-A PREROUTING -p tcp --dport 8000 -j DNAT --to-destination 172.17.0.101:8080`
第二条 SNAT：`-A POSTROUTING -s 172.17.0.0/24 -j MASQUERADE`
6 - tcp, 17 - udp
117,116 - TTL in second
TIME_WAIT - 连接状态
第一组四元组：连接发起方（原始方向，不会被修改）
第二组四元组：连接接收方（回复方向，会被 NAT 修改）


## [ipset](https://www.linuxjournal.com/content/advanced-firewall-configurations-ipset)

## nslookup/dig
PTR 反向解析:
```
nslookup -type=PTR 114.114.114.114 8.8.8.8
Server:		8.8.8.8
Address:	8.8.8.8#53

Non-authoritative answer:
114.114.114.114.in-addr.arpa	name = public1.114dns.com.

Authoritative answers can be found from:
```

```
$ dig +search nginx

; <<>> DiG 9.10.3-P4-Debian <<>> +search nginx
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 7778
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;nginx.default.svc.cluster.local. IN	A

;; ANSWER SECTION:
nginx.default.svc.cluster.local. 5 IN	A	192.168.32.111
nginx.default.svc.cluster.local. 5 IN	A	192.168.25.199
nginx.default.svc.cluster.local. 5 IN	A	192.168.37.165

;; Query time: 0 msec
;; SERVER: 172.16.0.10#53(172.16.0.10)
;; WHEN: Mon Aug 19 00:48:14 CST 2019
;; MSG SIZE  rcvd: 190
```

指定 DNS 服务器：
```
$ dig kubernetes.default.svc.cluster.local @10.32.0.10
```

## [tcpdump](https://www.tcpdump.org/manpages/tcpdump.1.html)
[pcap-filter](https://www.tcpdump.org/manpages/pcap-filter.7.html)

输出：
`时间戳 协议 源地址. 源端口 > 目的地址. 目的端口 网络包详细信息`

### TCP
`src > dst: Flags [tcpflags], seq data-seqno, ack ackno, win window, urg urgent, options [opts], length len`
tcpflags:
S (SYN), F (FIN), P (PUSH), R (RST), U (URG), W (ECN CWR), E (ECN-Echo) or `.` (ACK), or `none` if no flags are set.

```
$ tcpdump -nn port 8000
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on enp0s3, link-type EN10MB (Ethernet), capture size 262144 bytes
22:25:33.293232 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [S], seq 313536001, win 65535, options [mss 1460], length 0
22:25:33.293345 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [S.], seq 2466872099, ack 313536002, win 29200, options [mss 1460], length 0
22:25:33.293487 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [.], ack 1, win 65535, length 0
22:25:33.293511 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [P.], seq 1:79, ack 1, win 65535, length 78
22:25:33.293519 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [.], ack 79, win 29200, length 0
10.0.2.2 - - [24/Aug/2019 22:25:33] "GET / HTTP/1.1" 200 -
22:25:33.294800 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [P.], seq 1:156, ack 79, win 29200, length 155
22:25:33.295217 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [.], seq 156:1616, ack 79, win 29200, length 1460
22:25:33.295305 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [.], ack 156, win 65535, length 0
22:25:33.295423 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [P.], seq 1616:2071, ack 79, win 29200, length 455
22:25:33.295741 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [.], ack 1616, win 65535, length 0
22:25:33.295950 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [.], ack 2071, win 65535, length 0
22:25:33.296541 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [F.], seq 2071, ack 79, win 29200, length 0
22:25:33.298564 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [F.], seq 79, ack 2071, win 65535, length 0
22:25:33.298673 IP 10.0.2.15.8000 > 10.0.2.2.61689: Flags [.], ack 80, win 29200, length 0
22:25:33.298760 IP 10.0.2.2.61689 > 10.0.2.15.8000: Flags [F.], seq 79, ack 2072, win 65535, length 0
```
开始传输数据后，序号显示为数据流的偏移（-S可以显示原始序号），`seq 1:156` 表示发送第[1, 156)字节的数据，`ack 156` 表示确认了 156-1 字节的数据。双方不断确认收到的数据，所以 flags 都为 ACK 或 PUSH+ACK。

wireshark:
Statistics -> Conversations 根据协议层查看
Statistics -> Flow Graph 显示时序图
Right Click -> Follow TCP Stream 根据 steam （连接）过滤

## hping3
```
$ hping3 -c 3 -S -p 80 baidu.com
HPING baidu.com (enp0s3 39.156.69.79): S set, 40 headers + 0 data bytes
len=46 ip=39.156.69.79 ttl=64 id=50684 sport=80 flags=SA seq=0 win=65535 rtt=34.2 ms
len=46 ip=39.156.69.79 ttl=64 id=50686 sport=80 flags=SA seq=1 win=65535 rtt=42.2 ms
len=46 ip=39.156.69.79 ttl=64 id=50688 sport=80 flags=SA seq=2 win=65535 rtt=30.1 ms

--- baidu.com hping statistic ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 30.1/35.5/42.2 ms
```



# Tracing
## [perf](http://www.brendangregg.com/perf.html)
```
$ perf top -g
Samples: 510  of event 'cpu-clock', Event count (approx.): 100515577
  Children      Self  Shared Object            Symbol
+   23.99%     0.38%  [kernel]                 [k] seq_read
+   15.61%     0.76%  [kernel]                 [k] seq_printf
+   15.61%     0.38%  [kernel]                 [k] s_show
+   11.43%     2.67%  [kernel]                 [k] vsnprintf
+   10.66%    10.66%  perf                     [.] 0x000000000008d834
+    7.87%     7.87%  perf                     [.] 0x0000000000082287``
```

* Children: 符号调用其他符号占用比例之和
* Self: 符号本身所占比例
* Shared Object: 符号所在的共享对象
* Symbol: 符号名，`[k]` 内核空间，`[.]` 用户空间

```
$ perf record -ag -- sleep 2
$ perf report
```

统计性能事件：
```
$ perf stat -p <PID>
```

[火焰图](https://github.com/brendangregg/FlameGraph)分析：
```
$ perf script -i /root/perf.data | ./stackcollapse-perf.pl --all |  ./flamegraph.pl > perf.svg
```

跟踪内核函数调用：
```
$ perf probe --add 'do_sys_open filename:string'
$ perf record -e probe:do_sys_open -aR sleep 3
$ perf script
```

跟踪系统调用，类似 strace:
```
$ perf trace ls
```

跟踪用户函数，类似 ltrace：
```
$ perf probe -x /bin/bash 'readline%return +0($retval):string’
$ perf record -e probe_bash:readline__return -aR sleep 5
$ perf script
```

查询函数格式：
```
$ perf probe -V do_sys_open
$ perf probe -x /bin/bash -V readline
```

## strace
跟踪系统调用

* `-f` 除了跟踪当前进程外，还跟踪其子进程。
* `-o file` 将输出信息写到文件file中，而不是stderr。
* `-p pid` 绑定到一个由pid对应的正在运行的进程。
* `-r` 加上相对时间戳（消耗的时间）。
* `-t` 加上绝对时间戳。
* `-T` 显示系统调用时长。
* `-e` 指定系统调用名字。
* `-c` 统计各个系统调用的次数和时长。

## ltrace
跟踪调用库函数

* `-C` 解析C++名字粉碎的符号

## ftrace
挂载 debugfs: `mount -t debugfs nodev /sys/kernel/debug`
通过与 debugfs 的交互，完成跟踪：
```
$ cd /sys/kernel/debug/tracing
$ cat available_tracers
$ cat available_filter_functions
$ cat available_events
$ echo do_sys_open > set_graph_function
$ echo function_graph > current_tracer
$ echo funcgraph-proc > trace_options
$ echo 1 > tracing_on
$ ls
$ echo 0 > tracing_on
```

```
$ cat trace
# tracer: function_graph
#
CPU  TASK/PID         DURATION                  FUNCTION CALLS
|     |    |           |   |                     |   |   |   |
0)    ls-21699    |               |  do_sys_open() {
0)    ls-21699    |               |    getname() {
0)    ls-21699    |               |      getname_flags() {
0)    ls-21699    |               |        kmem_cache_alloc() {
0)    ls-21699    |   0.042 us    |          _cond_resched();
0)    ls-21699    |   0.509 us    |        }
0)    ls-21699    |   0.882 us    |      }
0)    ls-21699    |   1.180 us    |    }
0)    ls-21699    |               |    get_unused_fd_flags() {
0)    ls-21699    |               |      __alloc_fd() {
0)    ls-21699    |   0.087 us    |        _raw_spin_lock();
0)    ls-21699    |   0.056 us    |        expand_files();
0)    ls-21699    |   0.035 us    |        __pv_queued_spin_unlock();
0)    ls-21699    |   1.644 us    |      }
0)    ls-21699    |   2.007 us    |    }
...
```

或者用 trace-cmd:
```
$ trace-cmd record -p function_graph -g do_sys_open -O funcgraph-proc ls
$ trace-cmd report
version = 6
CPU 0 is empty
cpus=2
              ls-4157  [001] 707885.586231: funcgraph_entry:                   |  do_sys_open() {
              ls-4157  [001] 707885.586243: funcgraph_entry:                   |    getname() {
              ls-4157  [001] 707885.586244: funcgraph_entry:                   |      getname_flags() {
              ls-4157  [001] 707885.586244: funcgraph_entry:                   |        kmem_cache_alloc() {
              ls-4157  [001] 707885.586244: funcgraph_entry:                   |          _cond_resched() {
              ls-4157  [001] 707885.586244: funcgraph_entry:        0.039 us   |            rcu_note_context_switch();
              ls-4157  [001] 707885.586245: funcgraph_entry:        0.047 us   |            _raw_spin_lock_irq();
              ls-4157  [001] 707885.586245: funcgraph_entry:                   |            pick_next_task_fair() {
              ls-4157  [001] 707885.586245: funcgraph_entry:        0.043 us   |              update_curr();
              ls-4157  [001] 707885.586245: funcgraph_entry:        0.035 us   |              check_cfs_rq_runtime();
              ls-4157  [001] 707885.586246: funcgraph_entry:                   |              pick_next_entity() {
              ls-4157  [001] 707885.586246: funcgraph_entry:        0.041 us   |                wakeup_preempt_entity.isra.56();
              ls-4157  [001] 707885.586246: funcgraph_entry:        0.051 us   |                clear_buddies();
              ls-4157  [001] 707885.586246: funcgraph_exit:         0.622 us   |              }
...
```

## eBPF/BCC

## sysdig

## pstack

## pmap
显示进程的内存映射。`cat /proc/{pid}/maps,smaps`

## size
显示一个对象文件各段(.text, .data, .bss)大小
`size --format=sysv main`

## nm
显示文件里的符号

## objdump
显示文件里的对象信息

## lsof
显示打开的文件
```
$ lsof -p 2676
COMMAND  PID USER   FD      TYPE DEVICE SIZE/OFF    NODE NAME
tail    2676 root  cwd       DIR   0,45     4096 2492619 /
tail    2676 root  rtd       DIR   0,45     4096 2492619 /
tail    2676 root  txt       REG    8,1    64432 1968741 /usr/bin/tail
tail    2676 root  mem       REG    8,1          1968301 /lib/x86_64-linux-gnu/libc-2.23.so (path inode=2228725)
tail    2676 root  mem       REG    8,1          1968281 /lib/x86_64-linux-gnu/ld-2.23.so (path inode=2228701)
tail    2676 root    0u      CHR  136,0      0t0       3 /dev/pts/0
tail    2676 root    1u      CHR  136,0      0t0       3 /dev/pts/0
tail    2676 root    2u      CHR  136,0      0t0       3 /dev/pts/0
tail    2676 root    3r      CHR    1,3      0t0       6 /dev/null
tail    2676 root    4r  a_inode   0,11        0    6987 inotify
```

FD
u: 读写
r: 只读
w: 写

## ulimit
* `-s` 显示系统默认分配的.stack大小。
* `-a` 显示所有系统限制。
* `-c` 控制coredump大小，unlimited为无限制。
  * `/proc/sys/kernel/core_uses_pid`: 设为“1”，以pid为扩展名
  * `/proc/sys/kernel/core_pattern`: 设置目录及文件名格式: `/mycores/core-%e-%p-%t` 命令名-pid-时间戳

# Benchmark
## [fio](http://fio.readthedocs.io/en/latest/fio_doc.html)
单个大文件：
```
$ fio -name=randread -direct=1 -iodepth=64 -rw=randread -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=test1G
randread: (g=0): rw=randread, bs=4K-4K/4K-4K/4K-4K, ioengine=libaio, iodepth=64
fio-2.2.10
Starting 1 process
Jobs: 1 (f=1): [r(1)] [100.0% done] [35416KB/0KB/0KB /s] [8854/0/0 iops] [eta 00m:00s]
randread: (groupid=0, jobs=1): err= 0: pid=3825: Thu Aug 29 10:59:16 2019
  read : io=1024.0MB, bw=34004KB/s, iops=8500, runt= 30837msec
    slat (usec): min=41, max=2566, avg=114.84, stdev=32.80
    clat (usec): min=4, max=10583, avg=7382.59, stdev=534.81
     lat (usec): min=49, max=10725, avg=7497.62, stdev=541.48
    clat percentiles (usec):
     |  1.00th=[ 6432],  5.00th=[ 6624], 10.00th=[ 6752], 20.00th=[ 6880],
     | 30.00th=[ 7008], 40.00th=[ 7136], 50.00th=[ 7328], 60.00th=[ 7584],
     | 70.00th=[ 7712], 80.00th=[ 7840], 90.00th=[ 8032], 95.00th=[ 8160],
     | 99.00th=[ 8640], 99.50th=[ 9024], 99.90th=[ 9792], 99.95th=[10176],
     | 99.99th=[10432]
    bw (KB  /s): min=23656, max=37008, per=99.86%, avg=33955.15, stdev=2190.66
    lat (usec) : 10=0.01%, 100=0.01%, 250=0.01%, 500=0.01%, 750=0.01%
    lat (usec) : 1000=0.01%
    lat (msec) : 2=0.01%, 4=0.01%, 10=99.91%, 20=0.07%
  cpu          : usr=2.47%, sys=10.73%, ctx=262146, majf=0, minf=172
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, >=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, >=64=0.0%
     issued    : total=r=262144/w=0/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: io=1024.0MB, aggrb=34003KB/s, minb=34003KB/s, maxb=34003KB/s, mint=30837msec, maxt=30837msec
```

多个小文件：
```
$ fio --rw=randread --ioengine=sync --bs=4k --name=mytest --nrfiles=10000 --filesize=50k --direct=1 --openfiles=100
mytest: (g=0): rw=randread, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=1
fio-2.2.10
Starting 1 process
Jobs: 1 (f=4): [r(1)] [96.2% done] [6329KB/0KB/0KB /s] [1582/0/0 iops] [eta 00m:03s]s]
mytest: (groupid=0, jobs=1): err= 0: pid=6653: Thu Aug 29 14:43:28 2019
  read : io=480000KB, bw=6321.1KB/s, iops=1580, runt= 75926msec
    clat (usec): min=271, max=25059, avg=627.35, stdev=313.98
     lat (usec): min=271, max=25059, avg=627.60, stdev=313.98
    clat percentiles (usec):
     |  1.00th=[  346],  5.00th=[  406], 10.00th=[  450], 20.00th=[  506],
     | 30.00th=[  548], 40.00th=[  580], 50.00th=[  612], 60.00th=[  636],
     | 70.00th=[  668], 80.00th=[  708], 90.00th=[  772], 95.00th=[  836],
     | 99.00th=[ 1160], 99.50th=[ 1448], 99.90th=[ 4192], 99.95th=[ 6368],
     | 99.99th=[11328]
    bw (KB  /s): min= 4256, max= 9024, per=100.00%, avg=6324.31, stdev=815.62
    lat (usec) : 500=18.38%, 750=68.65%, 1000=11.07%
    lat (msec) : 2=1.65%, 4=0.14%, 10=0.09%, 20=0.01%, 50=0.01%
  cpu          : usr=0.61%, sys=3.01%, ctx=120691, majf=0, minf=478
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued    : total=r=120000/w=0/d=0, short=r=0/w=0/d=0, drop=r=0/w=0/d=0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: io=480000KB, aggrb=6321KB/s, minb=6321KB/s, maxb=6321KB/s, mint=75926msec, maxt=75926msec

Disk stats (read/write):
  rbd2: ios=119988/119, merge=0/4005, ticks=73429/1261, in_queue=1736, util=99.28%
```

* name: 测试任务名称
* rw: read, write, randread, randwrite
* direct: 直接读写
* iodepth: aio时，I/O 并发请求上限
* ioengine: sync, libaio, mmap, net
* bs: 每次 I/O 大小，direct 时应增大如 16m
* numjob: 任务进程数（并发数）
* group_reporting: 多个 numjob 时，合并显示结果
* filename: 生成文件名，如果是磁盘会破坏文件系统
* runtime: 限时
* fdatasync: 每次 I/O 后都执行 fdatasync
* size: 总大小
* nrfiles: 生成文件数目，格式 `jobname.jobnumber.filenumber`
* filesize: 生成文件大小
* openfiles: 同时 open 的文件数目

* slat: I/O 提交到执行的时长
* clat: I/O 提交到完成的时长
* lat: I/O 总时长
* bw: 吞吐量
* iops: 每秒 I/O

Ref: [aliyun storage test](https://help.aliyun.com/document_detail/25382.html?spm=5176.ecsbuyv3.0.0.122a3675KVZSlO)

IO 重放：
```
$ blktrace /dev/sdb # sdb.blktrace.0  sdb.blktrace.1
$ blkparse sdb -d sdb.bin
$ fio --name=replay --filename=/dev/sdb --direct=1 --read_iolog=sdb.bin
```

## dd
read
```
$ dd if=/tmp/testfile of=/dev/null bs=2M iflag=direct
```

write
```
$ dd if=/dev/zero of=/tmp/testfile bs=2M count=250 oflag=direct
```

`conv=fdatasync` 最后保证数据同步到磁盘。
`conv=fsync`: 同步数据及metadata。
`oflag=dsync`表示每次写操作都同步一次，不加参数则由系统自动同步。
`oflag=sync`同时对metadata。
`oflag=direct`使用direct i/o。

## iperf
服务端：
```
$ iperf3 -s -p 8000
Accepted connection from 192.168.1.29, port 60628
[  5] local 192.168.5.26 port 8999 connected to 192.168.1.29 port 60630
[ ID] Interval           Transfer     Bandwidth
[  5]   0.00-1.00   sec  96.0 MBytes   806 Mbits/sec
[  5]   1.00-2.00   sec   100 MBytes   840 Mbits/sec
[  5]   2.00-3.00   sec   100 MBytes   839 Mbits/sec
[  5]   3.00-4.00   sec   100 MBytes   839 Mbits/sec
[  5]   4.00-5.00   sec   100 MBytes   840 Mbits/sec
[  5]   5.00-5.04   sec  3.83 MBytes   781 Mbits/sec
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
[  5]   0.00-5.04   sec   501 MBytes   834 Mbits/sec  163             sender
[  5]   0.00-5.04   sec   500 MBytes   832 Mbits/sec                  receiver
```

客户端：
```
$ iperf3 -c 192.168.0.3 -4 -b 1G -t 5 -P 2 -p 8000 -i 1
Connecting to host 192.168.5.26, port 8999
[  4] local 192.168.1.29 port 60630 connected to 192.168.5.26 port 8999
[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd
[  4]   0.00-1.00   sec   102 MBytes   851 Mbits/sec   63    286 KBytes
[  4]   1.00-2.00   sec  99.7 MBytes   836 Mbits/sec   43    385 KBytes
[  4]   2.00-3.00   sec   100 MBytes   839 Mbits/sec   31    319 KBytes
[  4]   3.00-4.00   sec   101 MBytes   843 Mbits/sec    4    409 KBytes
[  4]   4.00-5.00   sec  99.8 MBytes   837 Mbits/sec   22    320 KBytes
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
[  4]   0.00-5.00   sec   501 MBytes   841 Mbits/sec  163             sender
[  4]   0.00-5.00   sec   500 MBytes   839 Mbits/sec                  receiver

iperf Done.
```

* 4: ipv4
* b: 目标带宽(b/s)
* t: 时长
* P: 并发数
* p: 端口
* i: 报告间隔

# proc
## 硬中断
```
$ cat /proc/interrupts
           CPU0       CPU1
  0:         45          0   IO-APIC   2-edge      timer
  1:         10          0   IO-APIC   1-edge      i8042
  8:          0          0   IO-APIC   8-edge      rtc0
  9:          0          0   IO-APIC   9-fasteoi   acpi
 12:        156          0   IO-APIC  12-edge      i8042
 14:          0          0   IO-APIC  14-edge      ata_piix
 15:        141     350947   IO-APIC  15-edge      ata_piix
 18:          0          0   IO-APIC  18-fasteoi   vboxvideo
 19:       1366     241260   IO-APIC  19-fasteoi   enp0s3
 20:         66     165278   IO-APIC  20-fasteoi   vboxguest
 21:       8418      29360   IO-APIC  21-fasteoi   0000:00:0d.0, snd_intel8x0
 22:         30         20   IO-APIC  22-fasteoi   ohci_hcd:usb1
NMI:          0          0   Non-maskable interrupts
LOC:    7953257    9485574   Local timer interrupts
SPU:          0          0   Spurious interrupts
PMI:          0          0   Performance monitoring interrupts
IWI:          1          2   IRQ work interrupts
RTR:          0          0   APIC ICR read retries
RES:    2991429    2971127   Rescheduling interrupts
CAL:      12982       5170   Function call interrupts
TLB:       4610       6489   TLB shootdowns
TRM:          0          0   Thermal event interrupts
THR:          0          0   Threshold APIC interrupts
DFR:          0          0   Deferred Error APIC interrupts
MCE:          0          0   Machine check exceptions
MCP:       1200       1200   Machine check polls
ERR:          0
MIS:          0
PIN:          0          0   Posted-interrupt notification event
PIW:          0          0   Posted-interrupt wakeup event
```

## 软中断
```
$ cat /proc/softirqs
                    CPU0       CPU1
          HI:          4          2
       TIMER:    7008308    4871695
      NET_TX:      26152     155054
      NET_RX:       1374     568992
       BLOCK:      21807     476499
BLOCK_IOPOLL:          0          0
     TASKLET:         30        797
       SCHED:    7023760    4900679
     HRTIMER:          0          0
         RCU:    1193798    4950543
```

# Reference
http://www.brendangregg.com/linuxperf.html

</xmp>
<script src="js/strapdown.js"></script>
</html>
